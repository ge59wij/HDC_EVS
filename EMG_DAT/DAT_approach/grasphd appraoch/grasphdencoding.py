import torch
import torchhd
from DAT_loadergrasp import GRASP_DAT_EventLoader
import os



class GraspHDEncoder:
    def __init__(self, height, width, dims, time_subwindow=10000, k=4, device=None):
        self.height = height
        self.width = width
        self.dims = dims
        self.time_subwindow = time_subwindow
        self.k = k      #  window size
        self.device = device if device else torch.device("cpu")


        '''6.11 Seed hvs Generation'''

        #1. Polarity random bipolar hvs h I + = - h I-:
        self.H_I_plus = torchhd.random(1, dims, "MAP", device=self.device).float()
        self.H_I_minus = -self.H_I_plus

        #2. 2D Position HVS, kxk frame approach: "assures thatthe resulting 2D position HV preserves the spatial correlation between events in the scene."
        self.corner_hvs = self._generate_corner_hvs()

        # 3. Timestamp Hypervectors: explained in Notion
        self.time_hvs = self._generate_time_hvs()

    def _generate_corner_hvs(self):
        """Generates only corner hypervectors"""
        num_rows = self.height // self.k + 1
        num_cols = self.width // self.k + 1
        torchhd.random(num_rows * num_cols, self.dims, "MAP", device=self.device).float().reshape(num_rows, num_cols,
                                                                                                  self.dims)
    def _generate_time_hvs(self, last_timestamp):
        """Generates timestamp hypervectors dynamically based on the actual last timestamp in the dataset."""
        num_time_bins = (last_timestamp // self.time_subwindow) + 1  # Compute bins dynamically
        return torchhd.random(num_time_bins, self.dims, "MAP", device=self.device).float()
    def get_position_hv(self, x, y): ##now: only generate (height//k + 1, width//k + 1) hypervectors instead of (height, width): On-Demand Generation
                                                                # aka interpolates between corner hypervectors only when needed, rather than storing everything in advance for each pixel => revise

        """##Dynamically### generates a position hypervector for pixel (x, y) using interpolation.
        ## Corner pixels in each block get randomly assigned hvs, Intermediate pixels are generated by interpolating between corner hvs
        #=> ensures that neighboring pixels have correlated hvs, preserving spatial smoothness
        #####experiment with k, not sure about their grid size, but they used k=2. their grid should be 200x250."""
        #1) Frame Division, paper page 9 defined by k in _generate_corner_hvs
        #2)Corner HVS:
        # Generate random hvs for the corner pixels, all random and orthogonal, check corner math again
        i = x // self.k
        j = y // self.k
        # Ensure boundary safety
        i_next = min(i + 1, self.corner_hvs.shape[0] - 1)
        j_next = min(j + 1, self.corner_hvs.shape[1] - 1)

        # Get the four corner hypervectors
        P00 = self.corner_hvs[i, j]
        P01 = self.corner_hvs[i, j_next]
        P10 = self.corner_hvs[i_next, j]
        P11 = self.corner_hvs[i_next, j_next]


        #3) Intermediate Hvs:
        # Interpolating for intermediate pixels: pixels in same ith window, get a HV by combining dims from 4 corners hvs
        ####### distance from corner ~ proportion of dim taken from each corner!
        '''#####example for k=2, Pixel corners: P00, P02 P20 P22
                
            2 P20 P21 P22
            1 P10 P11 P12
            0 P00 P01 P02
               0   1  2  
               
            for P01: 50% from P00 and 50% P02 (window edge). right and left pixels.
            for P11:center: 25%% from each corner.

            '''
        # Compute interpolation factors
        alpha_x = (x % self.k) / (self.k - 1) if self.k > 1 else 0.5
        alpha_y = (y % self.k) / (self.k - 1) if self.k > 1 else 0.5
        interpolated_hv = (
            (1 - alpha_x) * (1 - alpha_y) * P00 +
            alpha_x * (1 - alpha_y) * P10 +
            (1 - alpha_x) * alpha_y * P01 +
            alpha_x * alpha_y * P11
        )
        return interpolated_hv

    def get_time_hv(self, time, time_hvs):
        """Dynamically generates a timestamp hypervector for a given time value using alpha, interpolation."""
        i = time // self.time_subwindow
        i_next = min(i + 1, time_hvs.shape[0] - 1)

        # Get two closest timestamp hypervectors
        T_i = self.time_hvs[i]
        T_next = self.time_hvs[i_next]

        # Compute interpolation factor alpha
        alpha_t = (time % self.time_subwindow) / self.time_subwindow if self.time_subwindow > 1 else 0.5
        return (1 - alpha_t) * T_i + alpha_t * T_next

def interpolate_time_hv(T_start, T_end, alpha):
    """Interpolate between two hvs based on alpha position in time sub-window."""
    dims = T_start.shape[0]
    num_from_start = int((1 - alpha) * dims)
    return torch.cat((T_start[:num_from_start], T_end[num_from_start:]), dim=0)





def main():
    """Load dataset, encode few shuffled samples, and check similarity between class vectors."""
    device = "cpu"
    dataset_path = "/space/chair-nas/tosy/Gen3_Chifoumi_DAT/"
    split_name = "val"
    event_loader = GRASP_DAT_EventLoader(root_dir=dataset_path, split=split_name, delta_t=10000, shuffle=True)

    #print(event_loader[0])  # Correct format! :)

    encoded_vectors = []
    class_labels = []

    for sample_id, (filtered_events, class_id) in enumerate(event_loader):
        #  Extract the last timestamp properly
        last_timestamp = filtered_events[-1][0]  # First element of last row = last timestamp
        encoder = GraspHDEncoder(height=480, width=640, dims=8000, time_subwindow=10000, device=device)

        # Generate timestamp hypervectors dynamically for this sample
        time_hvs = encoder._generate_time_hvs(last_timestamp)

        # Example usage: Encode a time (e.g., 12ms)
        encoded_sample = encoder.get_time_hv(12000, time_hvs)

        encoded_vectors.append(encoded_sample)
        class_labels.append(class_id)
        print(f"Sample {sample_id} - Encoded Vector Shape: {encoded_sample.shape}, Class ID: {class_id}")

        if len(encoded_vectors) == 12:  # Limit to first x samples
            break
    # Convert to tensor for similarity analysis
    encoded_matrix = torch.stack(encoded_vectors)
    similarity_matrix = torch.nn.functional.cosine_similarity(encoded_matrix.unsqueeze(1), encoded_matrix.unsqueeze(0), dim=-1)
    print("\nCosine Similarity Between Encoded Vectors:")
    print(similarity_matrix)


if __name__ == "__main__":
    main()
